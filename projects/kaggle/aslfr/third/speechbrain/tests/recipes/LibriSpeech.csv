Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://www.dropbox.com/sh/qj2ps85g8oiicrj/AAAxlkQw5Pfo0M9EyHMi8iAra?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train_with_wav2vec.py,wer_ASR_train.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <3.5, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_sb_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=21 --number_of_epochs=2 --skip_prep=True --wav2vec2_hub=speechbrain/ssl-wav2vec2-base-librispeech,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://www.dropbox.com/sh/1ycv07gyxdq8hdl/AABUDYzza4SLYtY45RcGf2_0a?dl=0 https://www.dropbox.com/sh/a39wq3h60luv552/AABBnCM2Uf-CNax_cgMWdqDda?dl=0,https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --data_folder_rirs=tests/tmp,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_5000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://www.dropbox.com/sh/1ycv07gyxdq8hdl/AABUDYzza4SLYtY45RcGf2_0a?dl=0 https://www.dropbox.com/sh/a39wq3h60luv552/AABBnCM2Uf-CNax_cgMWdqDda?dl=0,https://huggingface.co/speechbrain/asr-crdnn-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --data_folder_rirs=tests/tmp,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000_sligru.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --data_folder_rirs=tests/tmp,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transducer/train.py,recipes/LibriSpeech/ASR/transducer/hparams/conformer_transducer.yaml,recipes/LibriSpeech/ASR/transducer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transducer/README.md,https://drive.google.com/drive/folders/1QtQz1Bkd_QPYnf3CyxhJ57ovbSZC2EhN?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --use_torchaudio=True --beam_size=1,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=1000, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transducer/train.py,recipes/LibriSpeech/ASR/transducer/hparams/conformer_transducer.yaml,recipes/LibriSpeech/ASR/transducer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transducer/README.md,https://drive.google.com/drive/folders/1QtQz1Bkd_QPYnf3CyxhJ57ovbSZC2EhN?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --use_torchaudio=False --beam_size=1,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=1000, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer_small.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/s0x6ni124858b8i/AAALaCH6sGTMRUVTjh8Tm8Jwa?dl=0,https://huggingface.co/speechbrain/asr-conformersmall-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <350, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/transformer.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/653kq8h2k87md4p/AAByAaAryXtQKpRzYtzV9ih5a?dl=0,https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=350, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_signal_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --use_language_modelling=False --ngram_lm_path=empty,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_conv_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --use_language_modelling=False --ngram_lm_path=empty,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_average_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --use_language_modelling=False --ngram_lm_path=empty,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_average_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 3 --upsampling=True --ctc_neurons=58 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --use_language_modelling=False --ngram_lm_path=empty,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_conv_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 3 --upsampling=True --ctc_neurons=58 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --use_language_modelling=False --ngram_lm_path=empty,
ASR,minilibrispeech,templates/speech_recognition/ASR/train.py,templates/speech_recognition/ASR/train.yaml,templates/speech_recognition/ASR/mini_librispeech_prepare.py,templates/speech_recognition/ASR/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --data_folder_rirs=tests/tmp,
Enhancement,minilibrispeech,templates/enhancement/train.py,templates/enhancement/train.yaml,templates/enhancement/mini_librispeech_prepare.py,templates/enhancement/README.md,,,--data_folder=tests/samples/separation --train_annotation=tests/samples/annotation/enhancement_train.json --valid_annotation=tests/samples/annotation/enhancement_dev.json --test_annotation=tests/samples/annotation/enhancement_dev.json --skip_prep=True --rir_folder=tests/tmp,
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/qmcl1obp8pxqaap/AAC3yXvjkfJ3mL-RKyAUxPdNa?dl=0,,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --lexicon_epochs=2 --skip_prep=True --phn_token_output=42 --use_tensorboard=False --debug,
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/zhrxg7anuhje7e8/AADTeJtdsja_wClkE2DsF9Ewa?dl=0,,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --lexicon_epochs=2 --skip_prep=True --phn_token_output=42 --use_tensorboard=False --debug,
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/pig0uk80xxii7cg/AACQ1rrRLYthvpNZ5FadPLtRa?dl=0,,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --train_data=tests/samples/annotation/ASR_train.json --valid_data=tests/samples/annotation/ASR_dev.json --test_data=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --phn_token_output=42,
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/tkf6di10edpz4i6/AAArnGAkE0bEEOvOGfc6KWuma?dl=0,,--data_folder=tests/samples/ASR/ --train_data=tests/samples/annotation/ASR_train.json --valid_data=tests/samples/annotation/ASR_dev.json --test_data=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --emb_dim=64 --debug,
LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/RNNLM.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://www.dropbox.com/sh/8xpybezuv70ibcg/AAByv2NuNv_ZFXuDdG89-MVPa?dl=0 https://www.dropbox.com/sh/8462ef441wvava2/AABNfHr07J_0SsdaM1yO5qkxa?dl=0 https://www.dropbox.com/sh/6uwqlw2tvv3kiy6/AACgvTR5jihyMrugBrpZPFNha?dl=0,,--data_folder=tests/samples/annotation/ --lm_corpus_path=tests/samples/annotation/LM_train.txt.gz --train_transcripts_pattern=LM_train.txt --dev_transcripts_pattern=LM_dev.txt --test_transcripts_pattern=LM_dev.txt --number_of_epochs=2,
LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/transformer.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://www.dropbox.com/sh/8xpybezuv70ibcg/AAByv2NuNv_ZFXuDdG89-MVPa?dl=0 https://www.dropbox.com/sh/8462ef441wvava2/AABNfHr07J_0SsdaM1yO5qkxa?dl=0 https://www.dropbox.com/sh/6uwqlw2tvv3kiy6/AACgvTR5jihyMrugBrpZPFNha?dl=0,,--data_folder=tests/samples/annotation/ --lm_corpus_path=tests/samples/annotation/LM_train.txt.gz --train_transcripts_pattern=LM_train.txt --dev_transcripts_pattern=LM_dev.txt --test_transcripts_pattern=LM_dev.txt --number_of_epochs=2,
Tokenizer,minilibrispeech,templates/speech_recognition/Tokenizer/train.py,templates/speech_recognition/Tokenizer/tokenizer.yaml,templates/speech_recognition/Tokenizer/mini_librispeech_prepare.py,templates/speech_recognition/Tokenizer/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --skip_prep=True --token_output=24 --annotation_read=wrd,
LM,minilibrispeech,templates/speech_recognition/LM/train.py,templates/speech_recognition/LM/RNNLM.yaml,templates/speech_recognition/mini_librispeech_prepare.py,templates/speech_recognition/README.md,,,--data_folder=tests/samples/ASR/ --lm_train_data=tests/samples/annotation/LM_train.txt --lm_valid_data=tests/samples/annotation/LM_dev.txt --lm_test_data=tests/samples/annotation/LM_dev.txt --number_of_epochs=2 --emb_dim=64 --rnn_size=128 --tokenizer_file=tests/tmp/LibriSpeech_row_24/24_unigram.model,
Speaker_recognition,minilibrispeech,templates/hyperparameter_optimization_speaker_id/train.py,templates/hyperparameter_optimization_speaker_id/train.yaml,templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py,templates/hyperparameter_optimization_speaker_id/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --n_classes=2 --emb_dim=42 --skip_prep=True --rir_folder=tests/tmp,
Speaker_recognition,minilibrispeech,templates/speaker_id/train.py,templates/speaker_id/train.yaml,templates/speaker_id/mini_librispeech_prepare.py,templates/speaker_id/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --n_classes=2 --emb_dim=42 --skip_prep=True --rir_folder=tests/tmp,
Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/1K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://www.dropbox.com/sh/xyifwhyq2o7g8u8/AACVHHgXUsRUZIfrzHOccLP7a?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23,
Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://www.dropbox.com/sh/xyifwhyq2o7g8u8/AACVHHgXUsRUZIfrzHOccLP7a?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23,
self-supervised-learning,LibriSpeech,recipes/LibriSpeech/self-supervised-learning/wav2vec2/train_sb_wav2vec2.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/LibriSpeech/self-supervised-learning/wav2vec2/librispeech_prepare.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_whisper.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_whisper_encoder.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --whisper_folder=tests/tmp/whisper_checkpoint,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train_with_whisper.py,recipes/LibriSpeech/ASR/transformer/hparams/train_hf_whisper.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --whisper_folder=tests/tmp/whisper_checkpoint,
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer_large.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]"
ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/branchformer_large.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]"
