### topology
n_stacks: 1
n_skips: 1
max_n_frames: 1600
conv_in_channel: 1
conv_channels: "32_32"
conv_kernel_sizes: "(3,3)_(3,3)"
conv_strides: "(1,1)_(1,1)"
conv_poolings: "(1,1)_(2,2)"
subsample: "1_1_1_2_1_1_1_2_1_1_1_1"
subsample_type: max_pool
enc_type: conv_uni_conformer
conformer_kernel_size: 7
conformer_normalization: layer_norm
enc_n_layers: 12
transformer_enc_pe_type: relative  ###
transformer_enc_clamp_len: 10  ###
transformer_enc_d_model: 256
transformer_enc_d_ff: 1024  ###
transformer_enc_n_heads: 4
attn_type: mocha
mocha_chunk_size: 4
mocha_init_r: -2  ###
mocha_eps: 1e-6
mocha_std: 1.0
mocha_1dconv: false
mocha_quantity_loss_weight: 0.2  ###
mocha_quantity_loss_start_epoch: 5
mocha_stableemit_weight: 0.2  ###
mocha_stableemit_start_epoch: 0  ###
attn_sharpening_factor: 1.0
attn_dim: 512
attn_n_heads: 1
dec_type: lstm
dec_n_units: 1024
dec_n_projs: 0
dec_n_layers: 1
dec_bottleneck_dim: 1024  ### this is effective
emb_dim: 512
tie_embedding: false
ctc_fc_list: "512"
### optimization
batch_size: 16000  # 12GB
# batch_size: 38000  # 24GB
batch_size_type: frame
optimizer: noam
n_epochs: 40
convert_to_sgd_epoch: 100
print_step: 8000  # 12GB
# print_step: 4000  # 24GB
metric: edit_distance
lr_factor: 5.0
early_stop_patient_n_epochs: 5
shuffle_bucket: true  ### this is important
sort_stop_epoch: 100
eval_start_epoch: 1
warmup_n_steps: 25000
accum_grad_n_steps: 16  # 12GB
# accum_grad_n_steps: 8  # 24GB
### initialization
param_init: 0.1
### regularization
clip_grad_norm: 5.0
dropout_in: 0.0
dropout_enc: 0.1
dropout_dec: 0.1
dropout_emb: 0.1
dropout_att: 0.0
weight_decay: 1e-6
lsm_prob: 0.1
### MTL
ctc_weight: 0.3
ctc_lsm_prob: 0.1
mtl_per_batch: false
task_specific_layer: false
# SpecAugment
freq_width: 13
n_freq_masks: 2
time_width: 50
n_time_masks: 2
time_width_upper: 1.0
