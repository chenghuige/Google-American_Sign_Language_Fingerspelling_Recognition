{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.append('/work/pikachu/utils/')\n",
    "sys.path.append('/work/pikachu/third/')\n",
    "sys.path.append('..')\n",
    "from gezi.common import *\n",
    "import gezi\n",
    "from src import config\n",
    "from src.config import *\n",
    "from src import util\n",
    "from src.dataset import Dataset\n",
    "from src.eval import eval_seq, calc_score\n",
    "from src.tf.decode import adjust_pad\n",
    "gezi.init_flags()\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "  tf.config.set_visible_devices([physical_devices[x] for x in range(4)], 'GPU')\n",
    "tf.config.set_soft_device_placement(True)\n",
    "for gpu in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "FLAGS.decode_phrase_type = False\n",
    "config.init()\n",
    "record_dir = f'{FLAGS.root}/tfrecords/0.1'\n",
    "records_pattern = f'{record_dir}/*.tfrec'\n",
    "files = gezi.list_files(records_pattern) \n",
    "FLAGS.valid_files = [x for x in files if int(os.path.basename(x).split('.')[0]) % FLAGS.folds == FLAGS.fold]\n",
    "dataset = Dataset('valid', files=FLAGS.valid_files)\n",
    "datas = dataset.make_batch(FLAGS.batch_size, return_numpy=True)\n",
    "from src.torch.dataset import get_dataloaders\n",
    "train_loader, eval_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "  'final-14layers.finetune',\n",
    "  'final-14layers.finetune.finetune_epochs-5',\n",
    "]\n",
    "model = models[0]\n",
    "model_dir = f'../working/offline/30/0/{model}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.restore_configs(model_dir)\n",
    "FLAGS.pad_rate = 0.9\n",
    "FLAGS.mn = 'souap'\n",
    "gezi.try_mkdir('../working/offline/30/0/souap')\n",
    "model = util.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lele.load_weights(model, f'{model_dir}/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15045"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16384x384 and 769x224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_steps \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mnum_steps\n\u001b[0;32m----> 2\u001b[0m metrics \u001b[39m=\u001b[39m eval_seq(eval_loader, model, num_steps)\n\u001b[1;32m      3\u001b[0m ic(metrics[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/eval.py:96\u001b[0m, in \u001b[0;36meval_seq\u001b[0;34m(dataset, model, steps)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m   \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 96\u001b[0m     y_ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minfer(frames)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m FLAGS\u001b[39m.\u001b[39mtorch:\n\u001b[1;32m     99\u001b[0m   \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m x:\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/models/encoder.py:100\u001b[0m, in \u001b[0;36mModel.infer\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer\u001b[39m(\u001b[39mself\u001b[39m, frames):\n\u001b[0;32m--> 100\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_(frames)\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/models/encoder.py:68\u001b[0m, in \u001b[0;36mModel.forward_\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_\u001b[39m(\u001b[39mself\u001b[39m, frames):\n\u001b[0;32m---> 68\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(frames)\n\u001b[1;32m     69\u001b[0m   \u001b[39m# self.feature = x\u001b[39;00m\n\u001b[1;32m     70\u001b[0m   \u001b[39mif\u001b[39;00m FLAGS\u001b[39m.\u001b[39meval_train \u001b[39mor\u001b[39;00m FLAGS\u001b[39m.\u001b[39mcenter_loss_rate \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m FLAGS\u001b[39m.\u001b[39mrdrop_key \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/models/encoder.py:65\u001b[0m, in \u001b[0;36mModel.encode\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, frames):\n\u001b[0;32m---> 65\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(frames)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/encoder.py:31\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, frames):\n\u001b[0;32m---> 31\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(frames)  \n\u001b[1;32m     32\u001b[0m   \u001b[39mif\u001b[39;00m FLAGS\u001b[39m.\u001b[39mencode_pool_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     33\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooling(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/encoders/squeezeformer2.py:749\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    748\u001b[0m   \u001b[39mif\u001b[39;00m FLAGS\u001b[39m.\u001b[39mtrans_emb:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[1;32m    750\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m    751\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pikachu/projects/kaggle/aslfr/jupyter/../src/torch/embedding.py:109\u001b[0m, in \u001b[0;36mSimpleEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 109\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[1;32m    110\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb_batchnorm:\n\u001b[1;32m    111\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_norm(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x384 and 769x224)"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "num_steps = dataset.num_steps\n",
    "metrics = eval_seq(eval_loader, model, num_steps)\n",
    "ic(metrics['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/22/23 21:07:07] 2899217480.py:1 in <module>\n",
      "                    metrics['score']: 0.7901512124256356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7901512124256356"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(metrics['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.state_dict()\n",
    "soups = {key:[] for key in model_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02465057373046875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d250496d4e46d7ac9e9c4873923fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, model_dir in tqdm(enumerate(models), total=len(models)):\n",
    "  lele.load_weights(model, f'../working/offline/30/0/{model_dir}/model.pt')\n",
    "  for k, v in model.state_dict().items():\n",
    "    soups[k].append(v)\n",
    "soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "model_dict.update(soups)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": true,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028971195220947266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "eval_loop",
       "rate": null,
       "total": 118,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a767eeaa2ca244c0bb22061329aeb917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval_loop:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/22/23 21:19:49] eval.py:186 in eval_seq()\n",
      "                    len(df): 15045\n",
      "                    len(df.idx.unique()): 15045\n",
      "[08/22/23 21:19:49] eval.py:187 in eval_seq()\n",
      "                    df.head(2):    sequence_id phrase_type  phrase_dup                   phrase_true  \\\n",
      "                                0    342890745     address           1               5301 kifer hill   \n",
      "                                1    344291439         url           1  https://gowestk.blogspot.com   \n",
      "                                \n",
      "                                                    phrase_pred  \\\n",
      "                                0               5301 kifor hill   \n",
      "                                1  https://gowestk.blogspot.com   \n",
      "                                \n",
      "                                                                          phrase_ori  char/max_idx  \\\n",
      "                                0  <PAD><PAD><PAD>5<PAD>33<PAD>0<PAD>1<PAD> <PAD>...            34   \n",
      "                                1  ht<PAD><PAD><PAD><PAD>ttppss://<PAD><PAD>/<PAD...            63   \n",
      "                                \n",
      "                                   char/ori_rate  char/true_rate  char/pred_rate  ...  phrase_len_rate    idx  \\\n",
      "                                0         0.4250        2.266667        2.266667  ...              1.0  10488   \n",
      "                                1         0.7875        2.250000        2.250000  ...              1.0  10500   \n",
      "                                \n",
      "                                   distance  acc/char  acc/type  acc/first  acc/last  n_frame  frame_mean  \\\n",
      "                                0         1  0.966102      True       True      True      117    0.172472   \n",
      "                                1         0  1.000000      True       True      True      234    0.202332   \n",
      "                                \n",
      "                                      score  \n",
      "                                0  0.933333  \n",
      "                                1  1.000000  \n",
      "                                \n",
      "                                [2 rows x 24 columns]\n",
      "[08/22/23 21:19:49] eval.py:226 in eval_seq()\n",
      "                    df2:       sequence_id phrase_type                     phrase_true  \\\n",
      "                         9115   1817195757       phone                    242-197-6202   \n",
      "                         9019   1817282569       phone                 +51-2721-208-63   \n",
      "                         9095   1817348598     address                  wildberries_ru   \n",
      "                         8982   1817370426     address                  projecteur-led   \n",
      "                         8965   1817672186       phone                    596-033-4046   \n",
      "                         9023   1817720859     address                        tampa fl   \n",
      "                         9126   1817740422     address  492288 west 28th terrace south   \n",
      "                         9105   1818613605         url          m-advice.co.jp/boosela   \n",
      "                         8968   1818712825     address          6169 valley view parks   \n",
      "                         9016   1818787239         url     neobychnye-muzei-mira/3585/   \n",
      "                         9170   1818872649         url            mio-footwear/refugee   \n",
      "                         9174   1819309566         url            tempemarketplace.com   \n",
      "                         9096   1819357924         url       https://www.cultifort.com   \n",
      "                         9056   1819369909     address                 polcathejourney   \n",
      "                         9129   1819442901     address             927 ernest surrency   \n",
      "                         8998   1819539423         url  fysiotherapiedewaard.nl/585685   \n",
      "                         9159   1819619498         url          www.zobozdrav-vestn.si   \n",
      "                         9071   1819636719         url       www.nexty-ele.com/6335967   \n",
      "                         9005   1819642365         url                      stars94.bg   \n",
      "                         8997   1819645763     address            1115 paradise meadow   \n",
      "                         \n",
      "                                                   phrase_pred  \\\n",
      "                         9115                         2617 660   \n",
      "                         9019                 +51-27121-208-63   \n",
      "                         9095                         wildems_   \n",
      "                         8982                            ee pa   \n",
      "                         8965                +5786-0-16840-044   \n",
      "                         9023                       tampla far   \n",
      "                         9126   492288 west 28th terrace south   \n",
      "                         9105                            acao/   \n",
      "                         8968                    w6w.lide iras   \n",
      "                         9016      neobychnye-muzei-mira/3585/   \n",
      "                         9170            bbice-geerer/reifurge   \n",
      "                         9174              tepemarketplace.com   \n",
      "                         9096       https://www.curptifort.com   \n",
      "                         9056                  polathe journey   \n",
      "                         9129              927 ernest surrency   \n",
      "                         8998  fysiotherapciedewaard.nl/585685   \n",
      "                         9159               6w/zobe_drive-vesn   \n",
      "                         9071         www.nety-ele.com/6335967   \n",
      "                         9005                       stars94.bg   \n",
      "                         8997              155 paradise meadow   \n",
      "                         \n",
      "                                                                      phrase_ori  phrase_len_true  \\\n",
      "                         9115  <PAD><PAD>2<PAD><PAD><PAD>11<PAD>77<PAD> 66<PA...               12   \n",
      "                         9019  +<PAD><PAD><PAD><PAD><PAD><PAD>55<PAD>1<PAD>--...               15   \n",
      "                         9095  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><...               14   \n",
      "                         8982  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><...               14   \n",
      "                         8965  +<PAD><PAD>557<PAD>8<PAD><PAD>6<PAD>--<PAD><PA...               12   \n",
      "                         9023  <PAD>ttammp<PAD>aa  f<PAD>ar<PAD><PAD><PAD><PA...                8   \n",
      "                         9126  <PAD><PAD>449922<PAD>2<PAD>8<PAD><PAD>88 wwest...               30   \n",
      "                         9105  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><...               22   \n",
      "                         8968  w<PAD><PAD>6<PAD><PAD>w<PAD><PAD><PAD><PAD><PA...               22   \n",
      "                         9016  <PAD><PAD><PAD>nn<PAD>e<PAD>oo<PAD>bb<PAD><PAD...               27   \n",
      "                         9170  <PAD><PAD><PAD>biic<PAD><PAD><PAD>--ge<PAD><PA...               20   \n",
      "                         9174  <PAD><PAD>t<PAD>e<PAD><PAD>p<PAD>ee<PAD><PAD><...               20   \n",
      "                         9096  hh<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>tt<P...               25   \n",
      "                         9056  ppoo<PAD>l<PAD><PAD>aattth<PAD>e  joouurrnnee<...               15   \n",
      "                         9129  <PAD><PAD><PAD><PAD><PAD>99<PAD><PAD><PAD><PAD...               19   \n",
      "                         8998  <PAD><PAD><PAD>f<PAD>y<PAD>ss<PAD>iio<PAD>tthh...               30   \n",
      "                         9159  <PAD><PAD>6<PAD><PAD>w<PAD><PAD><PAD>/<PAD><PA...               22   \n",
      "                         9071  w<PAD><PAD>w<PAD>w<PAD><PAD><PAD>..nnetttty-ee...               25   \n",
      "                         9005  <PAD><PAD><PAD>sstaa<PAD>rrss<PAD>9<PAD><PAD>4...               10   \n",
      "                         8997  <PAD><PAD>11<PAD><PAD>5<PAD>5  p<PAD>arra<PAD>...               20   \n",
      "                         \n",
      "                               phrase_len_pred  phrase_len_pred_  distance     score  \n",
      "                         9115                8                -1         7  0.416667  \n",
      "                         9019               16                -1         1  0.933333  \n",
      "                         9095                8                -1         7  0.500000  \n",
      "                         8982                5                -1        12  0.142857  \n",
      "                         8965               17                -1        10  0.166667  \n",
      "                         9023               10                -1         3  0.625000  \n",
      "                         9126               30                -1         0  1.000000  \n",
      "                         9105                5                -1        18  0.181818  \n",
      "                         8968               13                -1        16  0.272727  \n",
      "                         9016               27                -1         0  1.000000  \n",
      "                         9170               21                -1        13  0.350000  \n",
      "                         9174               19                -1         1  0.950000  \n",
      "                         9096               26                -1         2  0.920000  \n",
      "                         9056               15                -1         2  0.866667  \n",
      "                         9129               19                -1         0  1.000000  \n",
      "                         8998               31                -1         1  0.966667  \n",
      "                         9159               18                -1        11  0.500000  \n",
      "                         9071               24                -1         1  0.960000  \n",
      "                         9005               10                -1         0  1.000000  \n",
      "                         8997               19                -1         2  0.900000  \n",
      "[08/22/23 21:19:50] 1564651309.py:2 in <module>\n",
      "                    metrics['score']: 0.7901922926104217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7901922926104217"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture\n",
    "metrics = eval_seq(eval_loader, model, num_steps)\n",
    "ic(metrics['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
